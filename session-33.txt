
																Session - 33
															====================
															
															
			
VPN creation setup through console ( it is one time activity do it manually )





			
															
															
dont give bastion host access to developers if developers changed any configuration inside backend which leads to configuration issues bastion host accessed by devops engineer and admins only, but how developers to connect backend services for their testing like get requests atleast, so we have an option called     VPN      			 											



VPN : this is in your VPC network (developers VPN connect chesukoni manam nee network loney vunnamu ani ALB backend ki choopistundhi ) so that developers connect VPN and access backend ALB to test their GET requests 

developer --> VPN --> ALB backend   ( here developer laptop aws network lo vunnattlu when he connects from home )

Request flow :

developer --> VPN --> ALB backend ( SG allowed for VPN )
ALB backend --> VPN --> developers 

--> generally for VPN s seperatem team is there for every projects ( VPN s like cisco, citrix etc )

==> we have to create SG for VPN as well

#ports  22, 443, 1194,943 --> Vpn ports need to open 
module "vpn_sg" {
    source = "../../aws_sg_module"
    project_name = var.project_name
    environment = var.environment
    sg_name = "vpn"
    sg_description = "Created for bastion vpn instances in expense dev"
    vpc_id = data.aws_ssm_parameter.vpc_id.value
    common_tags = var.common_tags
}


creating resource aws_security_group_rule for VPN ( vpn_ssh, vpn_443 , vpn_943, vpn_1194) in sg.tf

--> we have to export pn sg_id value to ssm parameter store

in parameter.tf

resource "aws_ssm_parameter" "vpn_sg_id" {
  name  = "/${var.project_name}/${var.environment}/vpn_sg_id"
  type  = "String"
  value = module.vpn_sg.sg_id
}



VPN creation setup through console ( it is one time activity do it manually )
--------------------------------------------------------------------------------------------------------
in aws also vpn service is there but we dont want to go for that service ( it is bit confusion simply go for launch instance )

--> creation of VPN through console
	Launch instances --> browse amis --> search openvpnaccess server community ( ami ends with dea6f , open vpn access server community Image -fe8020db) --> attach key-pair --> select VPC, public subnet, Enable public IP, sg--> launch instances
	
--> we have to connect the vpn and do some configurations ( this is openvpnas distribution )
	openvpn --> ssh username
	openvpn, Openvpn@123 --> client credentials
	
1)	ssh -i .pem openvpnas@<public_IP>  --> do  yes, yes, enter again and again , yes, yes, yes, yes, set oopenvpn password as like 'OpenVpn@123', enter
	
2)	some urls appeared 
	give take Admin UI url and access from browser-->give login credentials( openvpn, Openvpn@123 )--> agree-->appeared open VPN console
	no more VPN settings required  ( already all settings given in step 1 like yes and enter )
	
	--> so now all VPN server setup completed it is up on running
		now we want vpn client software to connect the server
		download OpenVpn connect for windows software from 
		
		https://openvpn.net/client/client-connect-vpn-for-windows/
		
		open the client openvpnconnect software in laptop and get connected window appeared give url ( client UI url taken from cmd in step-2 )--> next--> apperaed import profile window (username is already there ) --> give password Openvpn@123--> select check box connect after import --> click IMPORT --> again it is asking password and give that --> now client is connected to server
		
		check my ip in browser it showing as i am in us-east-1 location ( it is hiding my location ) and the IP address is showing as open vpn IP address meaning that my laptop is in US location  ( checking what is my Ip in browser it is showing as openVpn Ip address) so hiding my laptop adrees through VPN completed
		
		
		
--> so now we can acess the backend ALB through VPN is possible,now developers connecting through vpn via SSH and get the APIs is possible through VPN

----------------------------------------------------------------------------------------------------------------------------------------------------------------



--> we have created sg for VPN but we have to add the rule in ALB backend also so that we will get the ALB response through VPN 

	app alb vochesi vpn source nunchi traffic ni accept cheyaali on port 80
	
	in sg.tf
	
	resource "aws_security_group_rule" "app_alb_vpn" {
  type              = "ingress"
  from_port         = 80
  to_port           = 80
  protocol          = "tcp"
  source_security_group_id = module.vpn_sg.sg_id
  security_group_id = module.app_alb_sg.sg_id
}

==> now we will get the default response in our laptop from ALB backend ( APP ALB ) through VPN ( check on browser to hit ALB DNS ( anything.app-dev.daws82s.online ) )

--> generally in companies developers have VPN acces they will access the private end points like private ALB, private backend urls for testing 

-----------------------------------------------------------------------------------------------------------------------------------------------------

every time lunching VPN instance through console is not recommended because it is a manual process we have automate through terraform to create VPN and for configurations inside VPN do it manually 

create

30-vpn

vpn.tf
variables.tf
data.tf
provider.tf
locals.tf

change values of owners and filter{ name, value} in data.tf
change aws_ssm_parameter give vpn_sg_id to get the VPN sg id 

goto vpn.tf
create VPN resorces as
-------------------------------------------------------------------------------------

resource "aws_instance" "vpn" {
  ami                    = data.aws_ami.openvpn.id # This is our devops-practice AMI ID
  vpc_security_group_ids = [data.aws_ssm_parameter.vpn_sg_id.value]
  instance_type          = "t2.micro"
  subnet_id = local.public_subnet_id
  tags = merge(
    var.common_tags,
    {
        Name = "${var.project_name}-${var.environment}-vpn"
    }
  )
}
-----------------------------------------------------------------------------------------

terraform init inside 30-vpn folder

now we have a problem to connect vpn we required key for that we have to generate key (ssh-keygen -f openvpnas) inside daws-82s folder 	
it will generate a pub and private key ( rename to .pem for private key )

create resource aws_key_pair  in vpn.tf 


resource "aws_key_pair" "openvpnas" {
  key_name   = "openvpnas"
  public_key = file("/c/devops/daws-82s/openvpnas.pub")     #  file("C:\\Devops\\daws-82s\\openvpnas.pub")  in programming give \\ for windows address 
}

here file() is used to read the file in that path and pass(paste) the content in public_key attribute
if that public key already there in aws key pairs give attribute as

key_name = aws_key_pair.openvpnas.key_name in aws_instance

-------------------------------------------------------------------------------------------------------------------

resource "aws_key_pair" "openvpnas" {
 
  key_name   = "openvpnas"   
  public_key = file("C:\\Devops\\daws-82s")
}



resource "aws_instance" "vpn" {
  ami                    = data.aws_ami.openvpn.id # This is our devops-practice AMI ID
  key_name = aws_key_pair.openvpnas.key_name     #  here public key attached to the instance 
  vpc_security_group_ids = [data.aws_ssm_parameter.vpn_sg_id.value]
  instance_type          = "t2.micro"
  subnet_id = local.public_subnet_id
  tags = merge(
    var.common_tags,
    {
        Name = "${var.project_name}-${var.environment}-vpn"
    }
  )
}




-----------------------------------------------------------------------------------------------------------------------

terraform init
terraform plan
terraform apply	


now connect "ssh -i .pem openvpnas@<public_IP>" (laptop --> VPN instance ( it is VPN server))
again it is asking some steps like

1)	ssh -i .pem openvpnas@<public_IP>  --> do  yes, yes, enter again and again , yes, yes, yes, yes, set oopenvpn password as like 'OpenVpn@123', enter


connected to vpn instance(VPN server)

now we have to connect the VPN server from OpenVPN client ( which is already installed on our laptop )

open the client openvpnconnect software in laptop and get connected window appeared give url ( client UI url taken from cmd in step-2 )--> next--> apperaed import profile window (username : openvpn ) --> give password Openvpn@123--> select check box connect after import --> click IMPORT --> again it is asking password and give that --> now client is connected to server

==> now we will get the default response in our laptop from ALB backend ( APP ALB ) through VPN ( check on browser to hit ALB DNS ( anything.app-dev.daws82s.online ) )

==> we can on and off the openvpn connect window because our laptop slow down  means that our all browsing requested goes to us VPN and --> amazon --> forward back to vpn --> laptop ( getting response ) so always stop when we are not used for VPN to connect APP ALB , our laptop may slowdown because of requests passing through VPN for ourbrowsing history

--> this is simple VPN for testing purpose 

------------------------------------------------------------------------------------------------------------------------------------------------------------

--> we have one time infra setup for RDS, ALB, jump/bastion host, VPN  ( means we have setup it for intial stage of project )

	after we have to setup backend,  frontend applications inside VPC
	
------------------------------------------------------------------------------------------------------------------------------------------------------------


	RDS setup 
========================

DB
=====
on premise lo DB setup
-----------------------------------

we have the DB developers, DB admins. they have to do

DB installations
DB upgrades
DB backups
DB changes
DB cluster setup ( configure many DB server (master-node setup) )
DB restoration test

cloud lo Db setup
-----------------------------
we have one service is there in aws i.e.,

		"RDS"
		
what that service is doing 

DB installations --> we just need to provide configurations
DB upgrades --> simple clicks
DB snapshots
DB cluster --> we can have replication controllers, high available, storage scalable 

these guarantees given by aws , here also Db team is there but as compared to on premise in cloud db team have not much work

creation of RDS service 
================================

got to RDS service 



for mysql we have already one sg is there
DB subnet group --> group of db subnets

we need DB subnet group in RDS creation process 

--> platoform engineers not included aws_db_subnet_group resource in module so we have to inform them like in your module not included this resource aws_db_subnet_group, so platform engineers understand the usage of the resource aws_db_subnet_group they discussed internally and they will inform  us to create this resource also in modules in next release like they are saying

for now we can create the resource of aws_db_subnet_group in vpc.tf
-------------------------------------------------------
# this can be included in modules 
resource "aws_db_subnet_group" "expense" {
  name       = "${var.project_name}-${var.environment}"
  subnet_ids = module.vpc.database_subnet_ids

  tags = merge(
    var.common_tags,
    {
      Name = "${var.project_name}-${var.environment}"
    }
  )
}
--------------------------------------------------------
in 00-vpc

terraform init,
terraform plan
terraform apply  ( to get the resource of aws_db_subnet_group in aws so we can use it for RDS creation process ) 

	RDS --> create database --> select mysql --> dont put check box Enable RDS Extended support ( aws will give you the support for RDS if mysql not giving support for us)--> Templates (free tier) --> give database name as expense-dev(DB instance identifier) --> Master username as root --> give Master password as ExpenseApp1 --> confirm password --> select our VPC (expense-vpc) --> select DB subnet group ( whatever we create in 'aws_db_subnet_group' throgh terraform ) --> select public access as no ( if we ant to access from Lpatop it is possible through VPN only )--> Existing VPC security group as our expense-dev-mysql sg --> AZ as 1a --> dont Enable Enhanced Monitoring ( charges incurred )  --> goto Database options give initial database name as transactions ( it is a schema )-->Backup dont enable automated backups ( charges incurred ) --> create database
	
	once databse created we will take the details from console
	DB_HOST_URL : endpoint url
	rootExpenseApp1
	3306
	
	we can connect this RDS databse through bastion for that create sg for mysql accepting bastion ( we have already selected this sg in rds creation )
	
	in sg.tf
	
resource "aws_security_group_rule" "mysql_bastion" {
  type              = "ingress"
  from_port         = 3306
  to_port           = 3306
  protocol          = "tcp"
  source_security_group_id = module.bastion_sg.sg_id
  security_group_id = module.mysql_sg.sg_id
}


terraform apply

-->once all set connect bastion host -->after connecting inside bastion -->install mysql client ( sudo dnf install mysql -y ) --> hit the end point of DB_HOST_URL ( mysql -h <end-point-url> -u root -pExpenseApp1--> now we are connected RDS ( mysql ) database through bastion it will appareed as mysql>--> give db commands like show databases ; it will appeared databses inside database

	
--> aws team how created this RDS service in background means they installed one ec2 instance and inside install mysql or any user db and whatever we provide the configurations in creation process they would take and create this RDS service through some automated scripts

--> we have some vendors for maintaing the databses in the market they will also follow the same procedure of aws team for RDS creation but they created ec2 instance install mysql and maintain upgrades to decrease the cost of RDS service and they will charge some percentage from ours ( but it is not recommended they were not secure so goto RDS only maintained by aws )

--> actually when the cloud comes it is an disadvantage to know how the services are created in the background in future generations dont know what the server is because of cloud

--> while creation of RDS module give deletion_protection as false because when it is true through terraform we cannot delete the databse so we can give it as false



	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
--> we can give comments for every resource creation ( if jeera ticket assigned for that resource mention jeera ticket id on the above resource comments )
	
	
